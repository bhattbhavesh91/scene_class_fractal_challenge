{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from random import shuffle\n",
    "import tensornets as nets\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scene_classes.csv', 'scene_train_images', 'scene_labels.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('hackthon-data/ai_train_64/ai_challenger_scene_train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.read_csv('hackthon-data/ai_train_64/ai_challenger_scene_train/scene_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53879, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df_a.loc[df_a.label_id != 'jsessionid=1B3094C4FF247D0E497F91743433395E?r='].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_a.label_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a.label_id = df_a.label_id.astype(int)\n",
    "df_a.drop(['index', 'Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79f993ae0858ae238b22968c5934d1ddba585ae4.jpg</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e963208fe9e90df0c385f7367bcdb6d0d5d0b165.jpg</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02df5ecbf7c749ccc9d833f129bbd5d9837940ce.jpg</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5620eb385b7567fb087813cf5233b5ceecdeeca3.jpg</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f8b4d42001a562fc63b9b39c02531661c0e236ca.jpg</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_id  label_id\n",
       "0  79f993ae0858ae238b22968c5934d1ddba585ae4.jpg        66\n",
       "1  e963208fe9e90df0c385f7367bcdb6d0d5d0b165.jpg        61\n",
       "2  02df5ecbf7c749ccc9d833f129bbd5d9837940ce.jpg        64\n",
       "3  5620eb385b7567fb087813cf5233b5ceecdeeca3.jpg        31\n",
       "4  f8b4d42001a562fc63b9b39c02531661c0e236ca.jpg        19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.read_csv('hackthon-data/ai_train_64/ai_challenger_scene_train/scene_classes.csv', header=None)\n",
    "df_b.drop(1, axis=1, inplace=True)\n",
    "df_b.rename({0:'label_id', 2: 'label_name'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_id</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>airport_terminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>landing_field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>airplane_cabin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>amusement_park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>skating_rink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_id        label_name\n",
       "0         0  airport_terminal\n",
       "1         1     landing_field\n",
       "2         2    airplane_cabin\n",
       "3         3    amusement_park\n",
       "4         4      skating_rink"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_a, df_b, on='label_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79f993ae0858ae238b22968c5934d1ddba585ae4.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>auto_showroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a74b20339e92d39e00920806f1aa6a3813d9481d.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>auto_showroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dc389691f5cd2233f1bda34940017b33ff386298.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>auto_showroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3584d24e091c6f3d79fa1d40f80f2789fac73b46.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>auto_showroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a27398da703ac3212858b7f9c442258203ffd8f.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>auto_showroom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_id  label_id     label_name\n",
       "0  79f993ae0858ae238b22968c5934d1ddba585ae4.jpg        66  auto_showroom\n",
       "1  a74b20339e92d39e00920806f1aa6a3813d9481d.jpg        66  auto_showroom\n",
       "2  dc389691f5cd2233f1bda34940017b33ff386298.jpg        66  auto_showroom\n",
       "3  3584d24e091c6f3d79fa1d40f80f2789fac73b46.jpg        66  auto_showroom\n",
       "4  2a27398da703ac3212858b7f9c442258203ffd8f.jpg        66  auto_showroom"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane_cabin',\n",
       " 'airport_terminal',\n",
       " 'amusement_park',\n",
       " 'aquarium',\n",
       " 'aqueduct',\n",
       " 'arena/performance',\n",
       " 'art_room',\n",
       " 'assembly_line',\n",
       " 'athletic_field',\n",
       " 'auto_showroom',\n",
       " 'balcony',\n",
       " 'banquet_hall',\n",
       " 'bar',\n",
       " 'baseball_field',\n",
       " 'basketball_court',\n",
       " 'bazaar',\n",
       " 'beauty_salon',\n",
       " 'bedchamber',\n",
       " 'bowling_alley',\n",
       " 'boxing_ring',\n",
       " 'bridge',\n",
       " 'campsite',\n",
       " 'church',\n",
       " 'classroom',\n",
       " 'clothing_store',\n",
       " 'coffee_shop',\n",
       " 'conference_room',\n",
       " 'construction_site',\n",
       " 'countryside',\n",
       " 'desert/sand',\n",
       " 'dining_room',\n",
       " 'discotheque',\n",
       " 'elevator/staircase',\n",
       " 'farm/farm_field',\n",
       " 'firefighting',\n",
       " 'football_field',\n",
       " 'forest',\n",
       " 'garden',\n",
       " 'gas_station',\n",
       " 'general_store',\n",
       " 'golf_course',\n",
       " 'greenhouse',\n",
       " 'gymnasium',\n",
       " 'hospital',\n",
       " 'igloo/ice_engraving',\n",
       " 'kitchen',\n",
       " 'laboratory',\n",
       " 'lake/river',\n",
       " 'landfill',\n",
       " 'landing_field',\n",
       " 'lawn',\n",
       " 'library/bookstore',\n",
       " 'mountain',\n",
       " 'museum',\n",
       " 'music_studio',\n",
       " 'nursery',\n",
       " 'ocean/beach',\n",
       " 'office',\n",
       " 'orchard/vegetable',\n",
       " 'palace',\n",
       " 'pasture',\n",
       " 'pavilion',\n",
       " 'plaza',\n",
       " 'racecourse',\n",
       " 'raft',\n",
       " 'recreation_room',\n",
       " 'repair_shop',\n",
       " 'residential_neighborhood',\n",
       " 'rodeo',\n",
       " 'skating_rink',\n",
       " 'ski_slope',\n",
       " 'soccer_field',\n",
       " 'station/platform',\n",
       " 'street',\n",
       " 'swimming_pool',\n",
       " 'television_studio',\n",
       " 'temple/east_asia',\n",
       " 'ticket_booth',\n",
       " 'tower',\n",
       " 'volleyball_court'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16480</th>\n",
       "      <td>6170cbea8b54c3aac36b3448135a2265a502d6a1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>airport_terminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16481</th>\n",
       "      <td>4da9ecb7c74d6170e6ac6ce20c7cc5a586f9485a.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>airport_terminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16482</th>\n",
       "      <td>0281566764968f1527b459bbda402ecf9e20ec40.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>airport_terminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16483</th>\n",
       "      <td>544c182febc40b01dce005b760b8dbd291fee718.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>airport_terminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16484</th>\n",
       "      <td>f2e160fdfbc3fc716b12629640b02e47f24d8889.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>airport_terminal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image_id  label_id  \\\n",
       "16480  6170cbea8b54c3aac36b3448135a2265a502d6a1.jpg         0   \n",
       "16481  4da9ecb7c74d6170e6ac6ce20c7cc5a586f9485a.jpg         0   \n",
       "16482  0281566764968f1527b459bbda402ecf9e20ec40.jpg         0   \n",
       "16483  544c182febc40b01dce005b760b8dbd291fee718.jpg         0   \n",
       "16484  f2e160fdfbc3fc716b12629640b02e47f24d8889.jpg         0   \n",
       "\n",
       "             label_name  \n",
       "16480  airport_terminal  \n",
       "16481  airport_terminal  \n",
       "16482  airport_terminal  \n",
       "16483  airport_terminal  \n",
       "16484  airport_terminal  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label_name == 'airport_terminal', :].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = mpimg.imread('hackthon-data/ai_challenger_scene_train/scene_train_images/6170cbea8b54c3aac36b3448135a2265a502d6a1.jpg')\n",
    "imgplot = plt.imshow(img1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('hackthon-data/ai_challenger_scene_train/scene_train_images/3584d24e091c6f3d79fa1d40f80f2789fac73b46.jpg')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_one_hot(data, nb_classes):\n",
    "    \"\"\"\n",
    "    Convert an iterable of indices to one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    targets = np.array(data).reshape(-1)\n",
    "    return np.eye(nb_classes)[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"hackthon-data/ai_train_64/ai_challenger_scene_train/scene_train_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79f993ae0858ae238b22968c5934d1ddba585ae4.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>auto_showroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a74b20339e92d39e00920806f1aa6a3813d9481d.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>auto_showroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dc389691f5cd2233f1bda34940017b33ff386298.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>auto_showroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3584d24e091c6f3d79fa1d40f80f2789fac73b46.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>auto_showroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a27398da703ac3212858b7f9c442258203ffd8f.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>auto_showroom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_id  label_id     label_name\n",
       "0  79f993ae0858ae238b22968c5934d1ddba585ae4.jpg        66  auto_showroom\n",
       "1  a74b20339e92d39e00920806f1aa6a3813d9481d.jpg        66  auto_showroom\n",
       "2  dc389691f5cd2233f1bda34940017b33ff386298.jpg        66  auto_showroom\n",
       "3  3584d24e091c6f3d79fa1d40f80f2789fac73b46.jpg        66  auto_showroom\n",
       "4  2a27398da703ac3212858b7f9c442258203ffd8f.jpg        66  auto_showroom"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of num random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "images = []\n",
    "for index, row in df.iterrows():\n",
    "    label.append(indices_to_one_hot(row['label_id'], 80))\n",
    "    images.append(cv2.imread(ROOT_PATH + row['image_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_array = np.array(images)\n",
    "labels_array = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('make_checkpoint_folders/images_array.npy', images_array)\n",
    "# np.save('make_checkpoint_folders/labels_array.npy', labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = labels_array.reshape(53876, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input_layer, filters, strides, is_training):\n",
    "    layer = tf.layers.conv2d(\n",
    "        inputs=input_layer, \n",
    "        filters=filters, \n",
    "        kernel_size=3,\n",
    "        strides=strides, \n",
    "        padding='same', \n",
    "        activation=None,\n",
    "        kernel_initializer=tf.truncated_normal_initializer()\n",
    "    )\n",
    "    \n",
    "    layer = tf.layers.batch_normalization(\n",
    "        inputs=layer, \n",
    "        axis=-1,\n",
    "        momentum=0.9,\n",
    "        epsilon=0.001,\n",
    "        center=True,\n",
    "        scale=True,\n",
    "    )\n",
    "    \n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def fully_connected(input_layer, num_units, is_training):\n",
    "    layer = tf.layers.dense(input_layer, num_units, use_bias=False, activation=None)\n",
    "    layer = tf.layers.batch_normalization(layer)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def conv_network(feature, label, num_class, image_size, keep_prob):\n",
    "    input_layer = tf.reshape(feature, [-1, image_size, image_size, 3])\n",
    "    \n",
    "    # 16 conv layers with 64, 128, 256, 512 filters.\n",
    "    layer = conv_layer(input_layer, 64, 1)\n",
    "    layer = conv_layer(layer, 64, 1, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 128, 1)\n",
    "    layer = conv_layer(layer, 128, 1)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 256, 2)\n",
    "    layer = conv_layer(layer, 256, 2)\n",
    "    layer = conv_layer(layer, 256, 2)\n",
    "    layer = conv_layer(layer, 256, 2)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 512, 2)\n",
    "    layer = conv_layer(layer, 512, 2)\n",
    "    layer = conv_layer(layer, 512, 2)\n",
    "    layer = conv_layer(layer, 512, 2)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 512, 2)\n",
    "    layer = conv_layer(layer, 512, 2)\n",
    "    layer = conv_layer(layer, 512, 2)\n",
    "    layer = conv_layer(layer, 512, 2)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    shape = layer.get_shape().as_list()\n",
    "    layer = tf.reshape(layer, shape=[-1, shape[1]*shape[2]*shape[3]])\n",
    "    layer = fully_connected(layer, 800)\n",
    "    layer = tf.nn.dropout(layer, keep_prob)\n",
    "    logits = tf.layers.dense(layer, 80)\n",
    "    output = tf.sigmoid(logits)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label))\n",
    "    \n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 80\n",
    "batch_size = 64\n",
    "image_size = 64\n",
    "max_step = 60000\n",
    "learning_rate =0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x = tf.placeholder(tf.float32, shape=(None, image_size, image_size, 3), name='input_x')\n",
    "y = tf.placeholder(tf.float32, shape=(None, num_class), name='output_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-210426093bcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-f843a27378c7>\u001b[0m in \u001b[0;36mconv_network\u001b[0;34m(feature, label, num_class, image_size, keep_prob)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconv_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# 16 conv layers with 64, 128, 256, 512 filters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   6480\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6481\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 6482\u001b[0;31m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   6483\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6484\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m               raise TypeError(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    508\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    540\u001b[0m     raise TypeError(\n\u001b[1;32m    541\u001b[0m         \"Element type not supported in TensorProto: %s\" % numpy_dtype.name)\n\u001b[0;32m--> 542\u001b[0;31m   \u001b[0mappend_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtensorflow/python/framework/fast_tensor_util.pyx\u001b[0m in \u001b[0;36mtensorflow.python.framework.fast_tensor_util.AppendObjectArrayToTensorProto\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 61\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got None"
     ]
    }
   ],
   "source": [
    "logits, loss = conv_network(images_array, labels_array, num_class, image_size, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    train_opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "       \n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init = tf.global_variables_initializer()\n",
    "# with tf.Session() as sess:\n",
    "#     # Run the initializer\n",
    "#     sess.run(init)\n",
    "#     for step in range(1, num_steps+1):\n",
    "#         batch_x, batch_y = next_batch(batch_size,images_array,labels_array)\n",
    "#         # Run optimization op (backprop)\n",
    "#         sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0})\n",
    "#         if step % display_step == 0 or step == 1:\n",
    "#             # Calculate batch loss and accuracy\n",
    "#             loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,Y: batch_y,keep_prob: dropout})\n",
    "#             print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "#                   \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "#                   \"{:.3f}\".format(acc))\n",
    "\n",
    "#     print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = './make_checkpoint_folders'\n",
    "saver = tf.train.Saver(max_to_keep=3)\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(save_model_path)\n",
    "    # Initializing the variables\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print('Restore the model from checkpoint {}.'.format(ckpt.model_checkpoint_path))\n",
    "        start_step = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print (start_step)\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        start_step = 0\n",
    "        print('Start training from new start.')        \n",
    "        print('global_variables_initializer ... done ...')\n",
    "        sess.run(logits.pretrained())\n",
    "        print('model.pretrained ... done ... ')\n",
    "\n",
    "    # Training cycle\n",
    "    print('starting training ... ')\n",
    "    for step in range(start_step, num_steps+1):\n",
    "        batch_x, batch_y = next_batch(batch_size,images_array,labels_array)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.5})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={x: batch_x,y: batch_y,keep_prob: dropout})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "        if step % 25 == 0:\n",
    "            saver.save(sess, \"make_checkpoint_folders/model.ckpt\", global_step=step)\n",
    "    print(\"Optimization Finished!\")\n",
    "    saver.save(sess, \"final-model.ckpt\", global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
